{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba41fd23-8d91-4366-b3d4-7145ef993869",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T16:53:18.059657Z",
     "iopub.status.busy": "2025-11-16T16:53:18.059298Z",
     "iopub.status.idle": "2025-11-16T16:53:21.895281Z",
     "shell.execute_reply": "2025-11-16T16:53:21.894676Z",
     "shell.execute_reply.started": "2025-11-16T16:53:18.059626Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/16 16:53:18 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh(<full-path-to-git-executable>)\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial message can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|silent|none|n|0: for no message or exception\n",
      "    - warn|w|warning|log|l|1: for a warning message (logging level CRITICAL, displayed by default)\n",
      "    - error|e|exception|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [SDK] Finding notebook path to set experiment...\n",
      "--- [SDK] Automatically setting experiment to: 'path-16500d19-4e2b-4c19-8446-edcac2d07833' ---\n",
      "--- [SDK] Starting run: ANEWnewRUN (ID: 4c8afe1b55a448a0a489c18e45d592ae) ---\n",
      "Attempting to register model MyAnotherModel.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/16 16:53:19 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected scikit-learn model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/11/16 16:53:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Registered model 'MyAnotherModel' already exists. Creating a new version of this model...\n",
      "2025/11/16 16:53:21 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: MyAnotherModel, version 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [SDK] Manually ending run: ANEWnewRUN ---\n",
      "üèÉ View run ANEWnewRUN at: http://mlflow-server:5000/#/experiments/63/runs/4c8afe1b55a448a0a489c18e45d592ae\n",
      "üß™ View experiment at: http://mlflow-server:5000/#/experiments/63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '3' of model 'MyAnotherModel'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# --- Train a scikit-learn model ---\n",
    "X, y = load_iris(return_X_y=True)\n",
    "sklearn_model = RandomForestClassifier().fit(X, y)\n",
    "\n",
    "my_custom_tags = {\n",
    "    \"tag\": 0.98,\n",
    "    \"model_type\": \"RandomForest\"\n",
    "}\n",
    "sdk.start_run(\"ANEWnewRUN\")\n",
    "sdk.register_model(sklearn_model, \"MyAnotherModel\", tags=my_custom_tags)\n",
    "sdk.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27ae7b31-62fc-4796-a7b1-34e38a74b351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dataset]: Run `pip install tqdm` to enable progress reporting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 11:29:03,237\tINFO parquet_datasource.py:725 -- Estimated parquet encoding ratio is 6.463.\n",
      "2025-11-16 11:29:03,238\tINFO parquet_datasource.py:785 -- Estimated parquet reader batch size at 163881 rows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset(\n",
       "   num_rows=?,\n",
       "   schema={\n",
       "      Table_id: int32,\n",
       "      Session_ID: int64,\n",
       "      Interface_ID: int32,\n",
       "      Session_Indicator: int32,\n",
       "      Start_Time_s: int64,\n",
       "      Start_Time_ms: int32,\n",
       "      End_Time_s: int64,\n",
       "      End_Time_ms: int32,\n",
       "      Protocol_Category: int32,\n",
       "      Protocol: int32,\n",
       "      Layer_7_Bearer_Protocol: int32,\n",
       "      MSISDN: int32,\n",
       "      IMSI: int32,\n",
       "      IMEI: int32,\n",
       "      Roaming_Type: int32,\n",
       "      Roaming_Direction: int32,\n",
       "      MS_IP_Address: string,\n",
       "      Server_IP_Address: string,\n",
       "      MS_Port: int32,\n",
       "      Server_Port: int32,\n",
       "      APN: string,\n",
       "      SGSN_Signaling_Plane_IP_Address: string,\n",
       "      GGSN_Signaling_Plane_IP_Address: string,\n",
       "      SGSN_User_Plane_IP_Address: string,\n",
       "      GGSN_User_Plane_IP_Address: string,\n",
       "      MCC: string,\n",
       "      MNC: string,\n",
       "      RAT: int32,\n",
       "      LAC: string,\n",
       "      RAC: string,\n",
       "      SAC: string,\n",
       "      CI: string,\n",
       "      Browser_Type: int32,\n",
       "      Uplink_Traffic: int64,\n",
       "      Downlink_Traffic: int64,\n",
       "      Network_Uplink_Traffic: int64,\n",
       "      Network_Downlink_Traffic: int64,\n",
       "      Uplink_Packets: int32,\n",
       "      Downlink_Packets: int32,\n",
       "      TCP_Connection_Status: int32,\n",
       "      TCP_Connection_Release_Status: int32,\n",
       "      TCP_Connect_RTT_ms: int64,\n",
       "      TCP_Uplink_Out_of_Order_Packets: int32,\n",
       "      TCP_Downlink_Out_of_Order_Packets: int32,\n",
       "      TCP_Uplink_Retransmitted_Packets: int32,\n",
       "      TCP_Downlink_Retransmitted_Packets: int32,\n",
       "      SYN_ACK_Failures_During_TCP_Handshakes: int32,\n",
       "      ACK_Failures_During_TCP_Handshakes: int32,\n",
       "      Host_Name: string,\n",
       "      First_URI_Visited: string,\n",
       "      Transaction_Type: int32,\n",
       "      First_GET_Success_or_Failure_Flag: int32,\n",
       "      First_GET_Transaction_Failure_Cause_Code: int32,\n",
       "      First_GET_Response_Delay: double,\n",
       "      GET_Transactions: int32,\n",
       "      Successful_GET_Transactions: int32,\n",
       "      POST_Transactions: int32,\n",
       "      Successful_POST_Transactions: int32,\n",
       "      Page_Browsing_Delay: double,\n",
       "      TAC: string,\n",
       "      ECI: string,\n",
       "      TCP_RTT_of_Step_1_ms: int32,\n",
       "      TCP_Uplink_Retransmitted_Packets_with_Payload: int32,\n",
       "      TCP_Downlink_Retransmitted_Packets_with_Payload: int32,\n",
       "      TCP_Uplink_Packets_with_Payload: int32,\n",
       "      TCP_Downlink_Packets_with_Payload: int32,\n",
       "      RAN_NE_User_Plane_IP_Address: string,\n",
       "      First_DNS_Response_Delay_Within_Page_ms: double,\n",
       "      First_DNS_Response_Code_Within_Page: int32,\n",
       "      Page_Size: int32,\n",
       "      First_Page_Response_Delay_ms: double,\n",
       "      MCC_of_Home_Carrier: string,\n",
       "      MNC_of_Home_Carrier: string,\n",
       "      User_Agent: string,\n",
       "      Uplink_Valid_Data_Transmission_Duration: double,\n",
       "      Downlink_Valid_Data_Transmission_Duration: double,\n",
       "      Device_Window_Size_Calculations: int32,\n",
       "      Device_Side_Small_Window_Times: int32,\n",
       "      Delay_Between_First_TCP_and_First_GET_ms: int32,\n",
       "      Delay_Between_First_GET_ACK_and_First_Data_Packet_ms: int32,\n",
       "      Average_Uplink_RTT: int32,\n",
       "      Average_Downlink_RTT: int32,\n",
       "      Number_of_Timer_Average_Uplink_RTT_Is_Longer_Than_500_ms: int32,\n",
       "      Number_of_Timer_Average_Downlink_RTT_Is_Longer_Than_1s: int32,\n",
       "      Uplink_RTT_Calculations: int32,\n",
       "      Downlink_RTT_Calculations: int32,\n",
       "      User_Side_Uplink_Lost_Packets: int32,\n",
       "      Server_Side_Uplink_Lost_Packets: int32,\n",
       "      Server_Side_Downlink_Lost_Packets: int32,\n",
       "      User_Side_Downlink_Lost_Packets: int32,\n",
       "      Downlink_TCP_Send_Window_Average_Size: int32,\n",
       "      Total_Downlink_TCP_Send_Window_Size_Calculations: int32,\n",
       "      Downlink_Maximum_TCP_Send_Window_Size: int32,\n",
       "      Total_Uplink_TCP_Send_Window_Average_Size: int32,\n",
       "      Total_Uplink_TCP_Send_Window_Size_Calculations: int32,\n",
       "      Uplink_Maximum_TCP_Send_Window_Size: int32,\n",
       "      Downlink_Continuous_Retransmission_Delay: int64,\n",
       "      User_Side_Hungry_Delay: int64,\n",
       "      Server_Side_Hunger_Delay: int64,\n",
       "      Signaling_Consumption_Flag_Signaling_Messages: int32,\n",
       "      First_RAT: int32,\n",
       "      Probe_Protocol: int32,\n",
       "      Visit_Type: int32,\n",
       "      Uplink_Valid_Traffic: int64,\n",
       "      Time_Zone: int32,\n",
       "      DST_Offset: int32,\n",
       "      Negotiated_Allocation_Retention_Priority: int32,\n",
       "      Allowed_Uplink_Maximum_Bit_Rate: int32,\n",
       "      Allowed_Downlink_Maximum_Bit_Rate: int32,\n",
       "      Negotiated_Traffic_Class: int32,\n",
       "      Negotiated_Handling_Traffic_Priority: int32,\n",
       "      Negotiated_QoS_Class_Identifier: int32,\n",
       "      Total_TCP_Connect_RTT_ms: int64,\n",
       "      Total_TCP_RTT_of_Step_1_ms: int64,\n",
       "      APP_ID: string,\n",
       "      probe_ID: string,\n",
       "      Record_type: string,\n",
       "      TCP_Uplink_Payload_Traffic: string,\n",
       "      TCP_Downlink_Payload_Traffic: string,\n",
       "      PAGE_SUCCEED_FLAG: int32,\n",
       "      PAGE_SR_SUCCEED_FLAG: string,\n",
       "      SP: string,\n",
       "      FIRSTDNSSUCFLAG: int32,\n",
       "      UFDR_Type: string,\n",
       "      DL_TRANS_DELAY: string,\n",
       "      UL_TRANS_DELAY: string,\n",
       "      AVG_UL_RTT_MICRO_SEC: string,\n",
       "      AVG_DW_RTT_MICRO_SEC: string,\n",
       "      ERROR_CODE_4xx_TIMES: int64,\n",
       "      ERROR_CODE_5xx_TIMES: int64,\n",
       "      GET_TIMEOUT_NUM: int64,\n",
       "      POST_TO_NUM: int64,\n",
       "      Flag: int32,\n",
       "      RECORD_DATE_TEHRAN: timestamp[ns]\n",
       "   }\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "sdk.read_data(\"s3://mybucket/data-delta/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4168a46d-eb38-4e6a-9b07-86d4f116cfb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_explorative_take_batch pid=722)\u001b[0m Estimated parquet encoding ratio is 6.463.\n",
      "\u001b[36m(_explorative_take_batch pid=722)\u001b[0m Estimated parquet reader batch size at 163881 rows\n",
      "\u001b[36m(_explorative_take_batch pid=722)\u001b[0m A new progress UI is available. To enable, set `ray.data.DataContext.get_current().enable_rich_progress_bars = True`.\n",
      "\u001b[36m(_explorative_take_batch pid=722)\u001b[0m Registered dataset logger for dataset dataset_1_0\n",
      "\u001b[36m(_explorative_take_batch pid=722)\u001b[0m Starting execution of Dataset dataset_1_0. Full logs are in /tmp/ray/session_2025-11-16_03-16-47_963361_7/logs/ray-data\n",
      "\u001b[36m(_explorative_take_batch pid=722)\u001b[0m Execution plan of Dataset dataset_1_0: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> LimitOperator[limit=2]\n",
      "\u001b[36m(_explorative_take_batch pid=722)\u001b[0m ‚ö†Ô∏è  Ray's object store is configured to use only 42.9% of available memory (11.2GiB out of 26.1GiB total). For optimal Ray Data performance, we recommend setting the object store to at least 50% of available memory. You can do this by setting the 'object_store_memory' parameter when calling ray.init() or by setting the RAY_DEFAULT_OBJECT_STORE_MEMORY_PROPORTION environment variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Table_id': array([3101, 3101], dtype=int32), 'Session_ID': array([1305130618271289494, 1305130623311911163]), 'Interface_ID': array([1, 1], dtype=int32), 'Session_Indicator': array([2, 1], dtype=int32), 'Start_Time_s': array([1754927850, 1754928354]), 'Start_Time_ms': array([ 64, 399], dtype=int32), 'End_Time_s': array([1754927851, 1754928355]), 'End_Time_ms': array([ 67, 769], dtype=int32), 'Protocol_Category': array([4, 4], dtype=int32), 'Protocol': array([48000, 48000], dtype=int32), 'Layer_7_Bearer_Protocol': array([0, 0], dtype=int32), 'MSISDN': array([nan, nan]), 'IMSI': array([nan, nan]), 'IMEI': array([nan, nan]), 'Roaming_Type': array([nan, nan]), 'Roaming_Direction': array([nan, nan]), 'MS_IP_Address': array(['102.184.186.42', '100.66.52.252'], dtype=object), 'Server_IP_Address': array(['212.23.201.122', '17.156.128.11'], dtype=object), 'MS_Port': array([63273, 61290], dtype=int32), 'Server_Port': array([3001,  443], dtype=int32), 'APN': array([None, None], dtype=object), 'SGSN_Signaling_Plane_IP_Address': array([None, None], dtype=object), 'GGSN_Signaling_Plane_IP_Address': array([None, None], dtype=object), 'SGSN_User_Plane_IP_Address': array([None, None], dtype=object), 'GGSN_User_Plane_IP_Address': array(['10.155.69.67', '10.155.65.21'], dtype=object), 'MCC': array([None, None], dtype=object), 'MNC': array([None, None], dtype=object), 'RAT': array([1, 1], dtype=int32), 'LAC': array([None, None], dtype=object), 'RAC': array([None, None], dtype=object), 'SAC': array([None, None], dtype=object), 'CI': array([None, None], dtype=object), 'Browser_Type': array([nan, nan]), 'Uplink_Traffic': array([  663, 11583]), 'Downlink_Traffic': array([  200, 10949]), 'Network_Uplink_Traffic': array([ 1011, 12771]), 'Network_Downlink_Traffic': array([  416, 12083]), 'Uplink_Packets': array([ 6, 22], dtype=int32), 'Downlink_Packets': array([ 4, 21], dtype=int32), 'TCP_Connection_Status': array([0, 0], dtype=int32), 'TCP_Connection_Release_Status': array([nan, nan]), 'TCP_Connect_RTT_ms': array([12, 12]), 'TCP_Uplink_Out_of_Order_Packets': array([0, 0], dtype=int32), 'TCP_Downlink_Out_of_Order_Packets': array([0, 1], dtype=int32), 'TCP_Uplink_Retransmitted_Packets': array([1, 0], dtype=int32), 'TCP_Downlink_Retransmitted_Packets': array([1, 0], dtype=int32), 'SYN_ACK_Failures_During_TCP_Handshakes': array([0, 0], dtype=int32), 'ACK_Failures_During_TCP_Handshakes': array([0, 0], dtype=int32), 'Host_Name': array([None, 'inappcheck.itunes.apple.com'], dtype=object), 'First_URI_Visited': array(['/api/v1/device-logs', 'inappcheck.itunes.apple.com'], dtype=object), 'Transaction_Type': array([ 3., nan]), 'First_GET_Success_or_Failure_Flag': array([nan, nan]), 'First_GET_Transaction_Failure_Cause_Code': array([nan, nan]), 'First_GET_Response_Delay': array([nan, nan]), 'GET_Transactions': array([nan, nan]), 'Successful_GET_Transactions': array([nan, nan]), 'POST_Transactions': array([nan, nan]), 'Successful_POST_Transactions': array([nan, nan]), 'Page_Browsing_Delay': array([nan, nan]), 'TAC': array([None, None], dtype=object), 'ECI': array([None, None], dtype=object), 'TCP_RTT_of_Step_1_ms': array([3, 2], dtype=int32), 'TCP_Uplink_Retransmitted_Packets_with_Payload': array([0, 0], dtype=int32), 'TCP_Downlink_Retransmitted_Packets_with_Payload': array([0, 0], dtype=int32), 'TCP_Uplink_Packets_with_Payload': array([ 1, 12], dtype=int32), 'TCP_Downlink_Packets_with_Payload': array([ 0, 11], dtype=int32), 'RAN_NE_User_Plane_IP_Address': array(['10.155.65.32', '10.1.129.152'], dtype=object), 'First_DNS_Response_Delay_Within_Page_ms': array([383., 970.]), 'First_DNS_Response_Code_Within_Page': array([0, 0], dtype=int32), 'Page_Size': array([ 761, 4447], dtype=int32), 'First_Page_Response_Delay_ms': array([nan, nan]), 'MCC_of_Home_Carrier': array([None, None], dtype=object), 'MNC_of_Home_Carrier': array([None, None], dtype=object), 'User_Agent': array([None, None], dtype=object), 'Uplink_Valid_Data_Transmission_Duration': array([ 1., 44.]), 'Downlink_Valid_Data_Transmission_Duration': array([ 1., 54.]), 'Device_Window_Size_Calculations': array([4, 8], dtype=int32), 'Device_Side_Small_Window_Times': array([0, 0], dtype=int32), 'Delay_Between_First_TCP_and_First_GET_ms': array([600, 777], dtype=int32), 'Delay_Between_First_GET_ACK_and_First_Data_Packet_ms': array([108, 111], dtype=int32), 'Average_Uplink_RTT': array([  3, 214], dtype=int32), 'Average_Downlink_RTT': array([356,  29], dtype=int32), 'Number_of_Timer_Average_Uplink_RTT_Is_Longer_Than_500_ms': array([0, 0], dtype=int32), 'Number_of_Timer_Average_Downlink_RTT_Is_Longer_Than_1s': array([0, 0], dtype=int32), 'Uplink_RTT_Calculations': array([1, 4], dtype=int32), 'Downlink_RTT_Calculations': array([1, 3], dtype=int32), 'User_Side_Uplink_Lost_Packets': array([0, 0], dtype=int32), 'Server_Side_Uplink_Lost_Packets': array([0, 0], dtype=int32), 'Server_Side_Downlink_Lost_Packets': array([0, 0], dtype=int32), 'User_Side_Downlink_Lost_Packets': array([0, 0], dtype=int32), 'Downlink_TCP_Send_Window_Average_Size': array([38020,  1398], dtype=int32), 'Total_Downlink_TCP_Send_Window_Size_Calculations': array([1, 6], dtype=int32), 'Downlink_Maximum_TCP_Send_Window_Size': array([65160, 28960], dtype=int32), 'Total_Uplink_TCP_Send_Window_Average_Size': array([10880,  4932], dtype=int32), 'Total_Uplink_TCP_Send_Window_Size_Calculations': array([4, 8], dtype=int32), 'Uplink_Maximum_TCP_Send_Window_Size': array([10880, 65535], dtype=int32), 'Downlink_Continuous_Retransmission_Delay': array([0, 0]), 'User_Side_Hungry_Delay': array([600,   4]), 'Server_Side_Hunger_Delay': array([ 17, 263]), 'Signaling_Consumption_Flag_Signaling_Messages': array([0, 0], dtype=int32), 'First_RAT': array([nan, nan]), 'Probe_Protocol': array([48001, 48001], dtype=int32), 'Visit_Type': array([3665, 3665], dtype=int32), 'Uplink_Valid_Traffic': array([  327, 10415]), 'Time_Zone': array([nan, nan]), 'DST_Offset': array([nan, nan]), 'Negotiated_Allocation_Retention_Priority': array([nan, nan]), 'Allowed_Uplink_Maximum_Bit_Rate': array([nan, nan]), 'Allowed_Downlink_Maximum_Bit_Rate': array([nan, nan]), 'Negotiated_Traffic_Class': array([nan, nan]), 'Negotiated_Handling_Traffic_Priority': array([nan, nan]), 'Negotiated_QoS_Class_Identifier': array([nan, nan]), 'Total_TCP_Connect_RTT_ms': array([360, 230]), 'Total_TCP_RTT_of_Step_1_ms': array([  3, 206]), 'APP_ID': array(['48001', '48001'], dtype=object), 'probe_ID': array(['13', '13'], dtype=object), 'Record_type': array(['0', '0'], dtype=object), 'TCP_Uplink_Payload_Traffic': array(['327', '10415'], dtype=object), 'TCP_Downlink_Payload_Traffic': array(['0', '9849'], dtype=object), 'PAGE_SUCCEED_FLAG': array([nan, nan]), 'PAGE_SR_SUCCEED_FLAG': array([None, None], dtype=object), 'SP': array(['Unknown', 'Unknown'], dtype=object), 'FIRSTDNSSUCFLAG': array([0, 0], dtype=int32), 'UFDR_Type': array([None, None], dtype=object), 'DL_TRANS_DELAY': array(['1', '638'], dtype=object), 'UL_TRANS_DELAY': array(['2', '1096'], dtype=object), 'AVG_UL_RTT_MICRO_SEC': array(['901', '573'], dtype=object), 'AVG_DW_RTT_MICRO_SEC': array(['486', '905'], dtype=object), 'ERROR_CODE_4xx_TIMES': array([nan, nan]), 'ERROR_CODE_5xx_TIMES': array([nan, nan]), 'GET_TIMEOUT_NUM': array([nan, nan]), 'POST_TO_NUM': array([nan, nan]), 'Flag': array([0, 0], dtype=int32), 'RECORD_DATE_TEHRAN': array(['2025-08-11T19:27:30.000000000', '2025-08-11T19:35:54.000000000'],\n",
      "      dtype='datetime64[ns]')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_explorative_take_batch pid=722)\u001b[0m ‚úîÔ∏è  Dataset dataset_1_0 execution finished in 10.61 seconds\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "print(ray.get(sdk.explorative_take_batch.remote(\"s3://mybucket/data-delta/\", 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c05bd7d0-6825-4342-8516-526ebaceb662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sdk.explorative_take_batch(\"s3://mybucket/data-delta/\", 2)\n",
    "# sdk.explorative_take_batch(sdk.read_data(\"s3://mybucket/data-delta/\"), 2)\n",
    "import ray\n",
    "# print(ray.get(sdk.explorative_take_batch.remote(\"s3://mybucket/data-delta/\", 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb1a4b53-bb85-4b46-8a04-82895609bc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing project files...\n",
      "['subfolder-2', 'mohamadsNotebook.ipynb', 'example1.dash', 'test.ipynb', 'yhg.ipynb', 'renderer.ipynb', 'salam.ipynb', 'README.md', 'train_test.ipynb', 'ipywidgets.ipynb', 'newModel.ipynb', 'xbox.ipynb', 'tmp.ipynb', 'example1.ipynb', 'panel.ipynb', 'collaboration.ipynb', 'MLflow_Tracking_URI', 'somethingggggg (Copy).ipynb', 'someOtherThingsOrNameOrSomethingElseOrChiz.ipynb', 'subfolder-1', 'ping.ipynb', 'matplotlib.ipynb']\n"
     ]
    }
   ],
   "source": [
    "# No 'import' needed! It's already loaded.\n",
    "from my_platform_sdk import sdk\n",
    "files = sdk.get_project_files()\n",
    "print(files)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25194afd-1e2e-4988-a865-ec102ffec228",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_explorative_take_batch pid=720)\u001b[0m Estimated parquet encoding ratio is 6.463.\n",
      "\u001b[36m(_explorative_take_batch pid=720)\u001b[0m Estimated parquet reader batch size at 163881 rows\n",
      "\u001b[36m(_explorative_take_batch pid=720)\u001b[0m A new progress UI is available. To enable, set `ray.data.DataContext.get_current().enable_rich_progress_bars = True`.\n",
      "\u001b[36m(_explorative_take_batch pid=720)\u001b[0m Registered dataset logger for dataset dataset_9_0\n",
      "\u001b[36m(_explorative_take_batch pid=720)\u001b[0m Starting execution of Dataset dataset_9_0. Full logs are in /tmp/ray/session_2025-11-15_08-18-32_003437_7/logs/ray-data\n",
      "\u001b[36m(_explorative_take_batch pid=720)\u001b[0m Execution plan of Dataset dataset_9_0: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> LimitOperator[limit=2]\n",
      "\u001b[36m(_explorative_take_batch pid=720)\u001b[0m ‚ö†Ô∏è  Ray's object store is configured to use only 42.9% of available memory (11.2GiB out of 26.1GiB total). For optimal Ray Data performance, we recommend setting the object store to at least 50% of available memory. You can do this by setting the 'object_store_memory' parameter when calling ray.init() or by setting the RAY_DEFAULT_OBJECT_STORE_MEMORY_PROPORTION environment variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Table_id': array([3101, 3101], dtype=int32), 'Session_ID': array([1305130618271289494, 1305130623311911163]), 'Interface_ID': array([1, 1], dtype=int32), 'Session_Indicator': array([2, 1], dtype=int32), 'Start_Time_s': array([1754927850, 1754928354]), 'Start_Time_ms': array([ 64, 399], dtype=int32), 'End_Time_s': array([1754927851, 1754928355]), 'End_Time_ms': array([ 67, 769], dtype=int32), 'Protocol_Category': array([4, 4], dtype=int32), 'Protocol': array([48000, 48000], dtype=int32), 'Layer_7_Bearer_Protocol': array([0, 0], dtype=int32), 'MSISDN': array([nan, nan]), 'IMSI': array([nan, nan]), 'IMEI': array([nan, nan]), 'Roaming_Type': array([nan, nan]), 'Roaming_Direction': array([nan, nan]), 'MS_IP_Address': array(['102.184.186.42', '100.66.52.252'], dtype=object), 'Server_IP_Address': array(['212.23.201.122', '17.156.128.11'], dtype=object), 'MS_Port': array([63273, 61290], dtype=int32), 'Server_Port': array([3001,  443], dtype=int32), 'APN': array([None, None], dtype=object), 'SGSN_Signaling_Plane_IP_Address': array([None, None], dtype=object), 'GGSN_Signaling_Plane_IP_Address': array([None, None], dtype=object), 'SGSN_User_Plane_IP_Address': array([None, None], dtype=object), 'GGSN_User_Plane_IP_Address': array(['10.155.69.67', '10.155.65.21'], dtype=object), 'MCC': array([None, None], dtype=object), 'MNC': array([None, None], dtype=object), 'RAT': array([1, 1], dtype=int32), 'LAC': array([None, None], dtype=object), 'RAC': array([None, None], dtype=object), 'SAC': array([None, None], dtype=object), 'CI': array([None, None], dtype=object), 'Browser_Type': array([nan, nan]), 'Uplink_Traffic': array([  663, 11583]), 'Downlink_Traffic': array([  200, 10949]), 'Network_Uplink_Traffic': array([ 1011, 12771]), 'Network_Downlink_Traffic': array([  416, 12083]), 'Uplink_Packets': array([ 6, 22], dtype=int32), 'Downlink_Packets': array([ 4, 21], dtype=int32), 'TCP_Connection_Status': array([0, 0], dtype=int32), 'TCP_Connection_Release_Status': array([nan, nan]), 'TCP_Connect_RTT_ms': array([12, 12]), 'TCP_Uplink_Out_of_Order_Packets': array([0, 0], dtype=int32), 'TCP_Downlink_Out_of_Order_Packets': array([0, 1], dtype=int32), 'TCP_Uplink_Retransmitted_Packets': array([1, 0], dtype=int32), 'TCP_Downlink_Retransmitted_Packets': array([1, 0], dtype=int32), 'SYN_ACK_Failures_During_TCP_Handshakes': array([0, 0], dtype=int32), 'ACK_Failures_During_TCP_Handshakes': array([0, 0], dtype=int32), 'Host_Name': array([None, 'inappcheck.itunes.apple.com'], dtype=object), 'First_URI_Visited': array(['/api/v1/device-logs', 'inappcheck.itunes.apple.com'], dtype=object), 'Transaction_Type': array([ 3., nan]), 'First_GET_Success_or_Failure_Flag': array([nan, nan]), 'First_GET_Transaction_Failure_Cause_Code': array([nan, nan]), 'First_GET_Response_Delay': array([nan, nan]), 'GET_Transactions': array([nan, nan]), 'Successful_GET_Transactions': array([nan, nan]), 'POST_Transactions': array([nan, nan]), 'Successful_POST_Transactions': array([nan, nan]), 'Page_Browsing_Delay': array([nan, nan]), 'TAC': array([None, None], dtype=object), 'ECI': array([None, None], dtype=object), 'TCP_RTT_of_Step_1_ms': array([3, 2], dtype=int32), 'TCP_Uplink_Retransmitted_Packets_with_Payload': array([0, 0], dtype=int32), 'TCP_Downlink_Retransmitted_Packets_with_Payload': array([0, 0], dtype=int32), 'TCP_Uplink_Packets_with_Payload': array([ 1, 12], dtype=int32), 'TCP_Downlink_Packets_with_Payload': array([ 0, 11], dtype=int32), 'RAN_NE_User_Plane_IP_Address': array(['10.155.65.32', '10.1.129.152'], dtype=object), 'First_DNS_Response_Delay_Within_Page_ms': array([383., 970.]), 'First_DNS_Response_Code_Within_Page': array([0, 0], dtype=int32), 'Page_Size': array([ 761, 4447], dtype=int32), 'First_Page_Response_Delay_ms': array([nan, nan]), 'MCC_of_Home_Carrier': array([None, None], dtype=object), 'MNC_of_Home_Carrier': array([None, None], dtype=object), 'User_Agent': array([None, None], dtype=object), 'Uplink_Valid_Data_Transmission_Duration': array([ 1., 44.]), 'Downlink_Valid_Data_Transmission_Duration': array([ 1., 54.]), 'Device_Window_Size_Calculations': array([4, 8], dtype=int32), 'Device_Side_Small_Window_Times': array([0, 0], dtype=int32), 'Delay_Between_First_TCP_and_First_GET_ms': array([600, 777], dtype=int32), 'Delay_Between_First_GET_ACK_and_First_Data_Packet_ms': array([108, 111], dtype=int32), 'Average_Uplink_RTT': array([  3, 214], dtype=int32), 'Average_Downlink_RTT': array([356,  29], dtype=int32), 'Number_of_Timer_Average_Uplink_RTT_Is_Longer_Than_500_ms': array([0, 0], dtype=int32), 'Number_of_Timer_Average_Downlink_RTT_Is_Longer_Than_1s': array([0, 0], dtype=int32), 'Uplink_RTT_Calculations': array([1, 4], dtype=int32), 'Downlink_RTT_Calculations': array([1, 3], dtype=int32), 'User_Side_Uplink_Lost_Packets': array([0, 0], dtype=int32), 'Server_Side_Uplink_Lost_Packets': array([0, 0], dtype=int32), 'Server_Side_Downlink_Lost_Packets': array([0, 0], dtype=int32), 'User_Side_Downlink_Lost_Packets': array([0, 0], dtype=int32), 'Downlink_TCP_Send_Window_Average_Size': array([38020,  1398], dtype=int32), 'Total_Downlink_TCP_Send_Window_Size_Calculations': array([1, 6], dtype=int32), 'Downlink_Maximum_TCP_Send_Window_Size': array([65160, 28960], dtype=int32), 'Total_Uplink_TCP_Send_Window_Average_Size': array([10880,  4932], dtype=int32), 'Total_Uplink_TCP_Send_Window_Size_Calculations': array([4, 8], dtype=int32), 'Uplink_Maximum_TCP_Send_Window_Size': array([10880, 65535], dtype=int32), 'Downlink_Continuous_Retransmission_Delay': array([0, 0]), 'User_Side_Hungry_Delay': array([600,   4]), 'Server_Side_Hunger_Delay': array([ 17, 263]), 'Signaling_Consumption_Flag_Signaling_Messages': array([0, 0], dtype=int32), 'First_RAT': array([nan, nan]), 'Probe_Protocol': array([48001, 48001], dtype=int32), 'Visit_Type': array([3665, 3665], dtype=int32), 'Uplink_Valid_Traffic': array([  327, 10415]), 'Time_Zone': array([nan, nan]), 'DST_Offset': array([nan, nan]), 'Negotiated_Allocation_Retention_Priority': array([nan, nan]), 'Allowed_Uplink_Maximum_Bit_Rate': array([nan, nan]), 'Allowed_Downlink_Maximum_Bit_Rate': array([nan, nan]), 'Negotiated_Traffic_Class': array([nan, nan]), 'Negotiated_Handling_Traffic_Priority': array([nan, nan]), 'Negotiated_QoS_Class_Identifier': array([nan, nan]), 'Total_TCP_Connect_RTT_ms': array([360, 230]), 'Total_TCP_RTT_of_Step_1_ms': array([  3, 206]), 'APP_ID': array(['48001', '48001'], dtype=object), 'probe_ID': array(['13', '13'], dtype=object), 'Record_type': array(['0', '0'], dtype=object), 'TCP_Uplink_Payload_Traffic': array(['327', '10415'], dtype=object), 'TCP_Downlink_Payload_Traffic': array(['0', '9849'], dtype=object), 'PAGE_SUCCEED_FLAG': array([nan, nan]), 'PAGE_SR_SUCCEED_FLAG': array([None, None], dtype=object), 'SP': array(['Unknown', 'Unknown'], dtype=object), 'FIRSTDNSSUCFLAG': array([0, 0], dtype=int32), 'UFDR_Type': array([None, None], dtype=object), 'DL_TRANS_DELAY': array(['1', '638'], dtype=object), 'UL_TRANS_DELAY': array(['2', '1096'], dtype=object), 'AVG_UL_RTT_MICRO_SEC': array(['901', '573'], dtype=object), 'AVG_DW_RTT_MICRO_SEC': array(['486', '905'], dtype=object), 'ERROR_CODE_4xx_TIMES': array([nan, nan]), 'ERROR_CODE_5xx_TIMES': array([nan, nan]), 'GET_TIMEOUT_NUM': array([nan, nan]), 'POST_TO_NUM': array([nan, nan]), 'Flag': array([0, 0], dtype=int32), 'RECORD_DATE_TEHRAN': array(['2025-08-11T19:27:30.000000000', '2025-08-11T19:35:54.000000000'],\n",
      "      dtype='datetime64[ns]')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_explorative_take_batch pid=720)\u001b[0m ‚úîÔ∏è  Dataset dataset_9_0 execution finished in 5.62 seconds\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "from typing import Callable, Dict, Iterator, Union\n",
    "import pyarrow\n",
    "import pandas\n",
    "import numpy\n",
    "ctx = ray.data.DataContext.get_current()\n",
    "ctx.execution_options.preserve_order = True\n",
    "import deltalake\n",
    "RANDOM_SEED = 42\n",
    "DATA_DEFAULT_BATCH_SIZE = 64\n",
    "\n",
    "def read_delta(delta_path:str):\n",
    "    ds = ray.data.read_delta(delta_path)\n",
    "    return ds\n",
    "    \n",
    "def preprocess_ds(ds:ray.data.Dataset, fn: Callable[[pyarrow.Table | pandas.DataFrame | Dict[str, numpy.ndarray]], pyarrow.Table | pandas.DataFrame | Dict[str, numpy.ndarray]] | Callable[[pyarrow.Table | pandas.DataFrame | Dict[str, numpy.ndarray]], Iterator[pyarrow.Table | pandas.DataFrame | Dict[str, numpy.ndarray]]]):\n",
    "    ds = ds.map_batches(fn)\n",
    "    return ds\n",
    "\n",
    "\n",
    "def read_data_internal(delta_path:str, preprocess_func:Callable[[pyarrow.Table | pandas.DataFrame | Dict[str, numpy.ndarray]], pyarrow.Table | pandas.DataFrame | Dict[str, numpy.ndarray]] | Callable[[pyarrow.Table | pandas.DataFrame | Dict[str, numpy.ndarray]], Iterator[pyarrow.Table | pandas.DataFrame | Dict[str, numpy.ndarray]]]=None):\n",
    "    ds = read_delta(delta_path)\n",
    "\n",
    "    if preprocess_func:\n",
    "        ds = preprocess_ds(ds, preprocess_func)\n",
    "\n",
    "    return ds\n",
    "\n",
    "## user facing function\n",
    "def _read_data(delta_path:str, preprocess_func:Callable[[pyarrow.Table | pandas.DataFrame | Dict[str, numpy.ndarray]], pyarrow.Table | pandas.DataFrame | Dict[str, numpy.ndarray]] | Callable[[pyarrow.Table | pandas.DataFrame | Dict[str, numpy.ndarray]], Iterator[pyarrow.Table | pandas.DataFrame | Dict[str, numpy.ndarray]]]=None):\n",
    "    return read_data_internal(delta_path, preprocess_func)\n",
    "\n",
    "# ## user facing function\n",
    "# @ray.remote\n",
    "# def _explorative_take_batch(ds:ray.data.Dataset, batch_size: int = DATA_DEFAULT_BATCH_SIZE, *, batch_format: str | None = 'default'):\n",
    "#     return ds.take_batch(batch_size=batch_size, batch_format=batch_format)\n",
    "\n",
    "## user facing function\n",
    "@ray.remote\n",
    "def _explorative_take_batch(delta_path:str, batch_size: int = DATA_DEFAULT_BATCH_SIZE, *, batch_format: str | None = 'default'):\n",
    "    ds = ray.data.read_delta(delta_path)\n",
    "    return ds.take_batch(batch_size=batch_size, batch_format=batch_format)\n",
    "\n",
    "## user facing function\n",
    "def _explorative_iter_batches(ds:ray.data.Dataset, batch_size: int = DATA_DEFAULT_BATCH_SIZE, *, batch_format: str | None = 'default'):\n",
    "    return ds.iter_batches(batch_size=batch_size, batch_format=batch_format, local_shuffle_seed=RANDOM_SEED)\n",
    "# print(_read_data(\"s3://mybucket/data-delta/\"))\n",
    "print(ray.get(_explorative_take_batch.remote(\"s3://mybucket/data-delta/\", 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f99fb0c-3ce4-490d-b379-641673c2a7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" This is a simple LinearRegression model training code for\n",
    "testing our mlflow server, this code was generated by AI. \"\"\"\n",
    "\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "MLFLOW_TRACKING_URI = \"http://127.0.0.1:5001\"\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "\n",
    "EXPERIMENT_NAME = \"MyMLOpsProject_V5\"\n",
    "ARTIFACT_PATH = \"file:///home/mohamad/Desktop/mlops_platform/my_mlflow_data\"\n",
    "\n",
    "try:\n",
    "    experiment_id = mlflow.create_experiment(\n",
    "        name=EXPERIMENT_NAME, \n",
    "        artifact_location=ARTIFACT_PATH\n",
    "    )\n",
    "except mlflow.exceptions.MlflowException as e:\n",
    "    experiment_id = mlflow.get_experiment_by_name(EXPERIMENT_NAME).experiment_id\n",
    "\n",
    "mlflow.set_experiment(experiment_id=experiment_id)\n",
    "\n",
    "DB_URL = \"postgresql://mlflow_user:mlflow_pass@localhost:5432/app_data\"\n",
    "\n",
    "def get_data_from_db():\n",
    "    print(f\"Connecting to DB at {DB_URL}...\")\n",
    "    try:\n",
    "        engine = create_engine(DB_URL)\n",
    "        query = \"SELECT feature_1, feature_2, target FROM model_data\"\n",
    "        df = pd.read_sql(query, engine)\n",
    "        print(\"Data loaded successfully from Postgres:\")\n",
    "        print(df.head())\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to DB or fetching data: {e}\")\n",
    "        return None\n",
    "\n",
    "def train_model(df):\n",
    "    print(\"Starting model training...\")\n",
    "\n",
    "    with mlflow.start_run() as run:\n",
    "        X = df[['feature_1', 'feature_2']]\n",
    "        y = df['target']\n",
    "\n",
    "        n_estimators = 10\n",
    "        mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "\n",
    "        model = LinearRegression()\n",
    "        model.fit(X, y)\n",
    "\n",
    "        score = model.score(X, y)\n",
    "        print(f\"Model Score (R2): {score}\")\n",
    "\n",
    "        mlflow.log_metric(\"r2_score\", score)\n",
    "\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=model,\n",
    "            artifact_path=\"model_artifacts\",\n",
    "            registered_model_name=\"ANewModel\"\n",
    "        )\n",
    "\n",
    "        print(f\"Model logged successfully with run ID: {run.info.run_id}\")\n",
    "        print(f\"View this run in MLflow UI: {MLFLOW_TRACKING_URI}/#/experiments/{run.info.experiment_id}/runs/{run.info.run_id}\")\n",
    "\n",
    "data = get_data_from_db()\n",
    "if data is not None:\n",
    "    train_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "377c9f7c-f9bf-405f-9b0e-603188100ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [MLOps Platform SDK] ---\n",
      "SDK successfully loaded!\n",
      "MLflow Tracking Server: http://mlflow-server:5000\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for |: 'type' and 'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmy_platform_sdk\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sdk\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# This works perfectly:\u001b[39;00m\n\u001b[1;32m      4\u001b[0m sdk\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmy-data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/app/my_platform_sdk/__init__.py:95\u001b[0m\n\u001b[1;32m     92\u001b[0m     ds \u001b[38;5;241m=\u001b[39m ray\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mread_delta(delta_path)\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ds\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpreprocess_ds\u001b[39m(ds:ray\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset, fn: Callable[[\u001b[43mpyarrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTable\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpandas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m \u001b[38;5;241m|\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, numpy\u001b[38;5;241m.\u001b[39mndarray]], pyarrow\u001b[38;5;241m.\u001b[39mTable \u001b[38;5;241m|\u001b[39m pandas\u001b[38;5;241m.\u001b[39mDataFrame \u001b[38;5;241m|\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, numpy\u001b[38;5;241m.\u001b[39mndarray]] \u001b[38;5;241m|\u001b[39m Callable[[pyarrow\u001b[38;5;241m.\u001b[39mTable \u001b[38;5;241m|\u001b[39m pandas\u001b[38;5;241m.\u001b[39mDataFrame \u001b[38;5;241m|\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, numpy\u001b[38;5;241m.\u001b[39mndarray]], Iterator[pyarrow\u001b[38;5;241m.\u001b[39mTable \u001b[38;5;241m|\u001b[39m pandas\u001b[38;5;241m.\u001b[39mDataFrame \u001b[38;5;241m|\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, numpy\u001b[38;5;241m.\u001b[39mndarray]]]):\n\u001b[1;32m     96\u001b[0m     ds \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mmap_batches(fn)\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for |: 'type' and 'type'"
     ]
    }
   ],
   "source": [
    "from my_platform_sdk import sdk\n",
    "\n",
    "# This works perfectly:\n",
    "sdk.read(\"my-data\")\n",
    "sdk.write(\"my-predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c46fa62-820e-4871-8690-cee5d1c16f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed: Cannot overwrite SDK attribute 'read'. The platform SDK is read-only.\n"
     ]
    }
   ],
   "source": [
    "def _read(name):\n",
    "    print(\"I'm trying to hack the read function!\")\n",
    "\n",
    "try:\n",
    "    sdk.read = my_new_read\n",
    "except AttributeError as e:\n",
    "    print(f\"Failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dd978d8-08d8-463f-b8c3-7e2fd1db7cec",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sdk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msdk\u001b[49m\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m12\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sdk' is not defined"
     ]
    }
   ],
   "source": [
    "sdk.read(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80203551-ae94-451c-8e5d-226b4aad5871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a43bd35-4c40-4e1d-bea1-ebeca685b8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [MLOps Platform SDK] ---\n",
      "SDK successfully loaded!\n",
      "MLflow Tracking Server: http://mlflow-server:5000\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for |: 'type' and 'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmy_platform_sdk\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sdk\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# This works perfectly:\u001b[39;00m\n\u001b[1;32m      4\u001b[0m sdk\u001b[38;5;241m.\u001b[39mread_data(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmy-data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/app/my_platform_sdk/__init__.py:95\u001b[0m\n\u001b[1;32m     92\u001b[0m     ds \u001b[38;5;241m=\u001b[39m ray\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mread_delta(delta_path)\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ds\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpreprocess_ds\u001b[39m(ds:ray\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset, fn: Callable[[\u001b[43mpyarrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTable\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpandas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m \u001b[38;5;241m|\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, numpy\u001b[38;5;241m.\u001b[39mndarray]], pyarrow\u001b[38;5;241m.\u001b[39mTable \u001b[38;5;241m|\u001b[39m pandas\u001b[38;5;241m.\u001b[39mDataFrame \u001b[38;5;241m|\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, numpy\u001b[38;5;241m.\u001b[39mndarray]] \u001b[38;5;241m|\u001b[39m Callable[[pyarrow\u001b[38;5;241m.\u001b[39mTable \u001b[38;5;241m|\u001b[39m pandas\u001b[38;5;241m.\u001b[39mDataFrame \u001b[38;5;241m|\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, numpy\u001b[38;5;241m.\u001b[39mndarray]], Iterator[pyarrow\u001b[38;5;241m.\u001b[39mTable \u001b[38;5;241m|\u001b[39m pandas\u001b[38;5;241m.\u001b[39mDataFrame \u001b[38;5;241m|\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, numpy\u001b[38;5;241m.\u001b[39mndarray]]]):\n\u001b[1;32m     96\u001b[0m     ds \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mmap_batches(fn)\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for |: 'type' and 'type'"
     ]
    }
   ],
   "source": [
    "from my_platform_sdk import sdk\n",
    "\n",
    "# This works perfectly:\n",
    "sdk.read_data(\"my-data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e74f7455-2653-495d-b2f7-3f2279b56937",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T16:02:13.344063Z",
     "iopub.status.busy": "2025-11-12T16:02:13.343447Z",
     "iopub.status.idle": "2025-11-12T16:02:13.357148Z",
     "shell.execute_reply": "2025-11-12T16:02:13.355706Z",
     "shell.execute_reply.started": "2025-11-12T16:02:13.344006Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now we are able to read data from datasource something_data_data_data the data which we need!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'fetch data of something_data_data_data'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdk.read(\"something_data_data_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0728011-5967-498c-bc24-b83a64971468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [SDK] Finding notebook path to set experiment...\n",
      "--- [SDK] Automatically setting experiment to: 'salam.ipynb' ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/16 06:07:42 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh(<full-path-to-git-executable>)\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial message can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|silent|none|n|0: for no message or exception\n",
      "    - warn|w|warning|log|l|1: for a warning message (logging level CRITICAL, displayed by default)\n",
      "    - error|e|exception|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n",
      "2025/11/16 06:07:43 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [SDK] Starting run: ANEWRUN (ID: 1a64ff44ac2b420a99ec7fd760d4dab3) ---\n",
      "Attempting to register model MyModel.\n",
      "Detected scikit-learn model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/11/16 06:07:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Registered model 'MyModel' already exists. Creating a new version of this model...\n",
      "2025/11/16 06:07:48 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: MyModel, version 11\n",
      "Created version '11' of model 'MyModel'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [SDK] Manually ending run: ANEWRUN ---\n",
      "üèÉ View run ANEWRUN at: http://mlflow-server:5000/#/experiments/62/runs/1a64ff44ac2b420a99ec7fd760d4dab3\n",
      "üß™ View experiment at: http://mlflow-server:5000/#/experiments/62\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# --- Train a scikit-learn model ---\n",
    "X, y = load_iris(return_X_y=True)\n",
    "sklearn_model = RandomForestClassifier().fit(X, y)\n",
    "\n",
    "my_custom_tags = {\n",
    "    \"tag\": 0.98,\n",
    "    \"model_type\": \"RandomForest\"\n",
    "}\n",
    "sdk.start_run(\"ANEWRUN\")\n",
    "sdk.register_model(sklearn_model, \"MyModel\", tags=my_custom_tags)\n",
    "sdk.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d535e447-cabc-455c-b7df-6b8345d82437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_model(name):\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77dffc48-2e6c-4748-89ed-e6887c98846d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.register_model(name)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "register_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f96decf4-ba7a-41cc-8ec8-0e4200fe8fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed: Cannot overwrite SDK attribute 'register_model'. The platform SDK is read-only.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    sdk.register_model = register_model\n",
    "except AttributeError as e:\n",
    "    print(f\"Failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bba650f-1e4c-4e7d-b4a4-0d32ab4cb413",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T14:05:22.306451Z",
     "iopub.status.busy": "2025-11-10T14:05:22.305856Z",
     "iopub.status.idle": "2025-11-10T14:05:22.677485Z",
     "shell.execute_reply": "2025-11-10T14:05:22.676483Z",
     "shell.execute_reply.started": "2025-11-10T14:05:22.306389Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'jjk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mjjk\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'jjk' is not defined"
     ]
    }
   ],
   "source": [
    "jjk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba2018a5-7b34-47ca-ba62-1bdfdb7404d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T15:57:11.334790Z",
     "iopub.status.busy": "2025-11-12T15:57:11.334005Z",
     "iopub.status.idle": "2025-11-12T15:57:11.347834Z",
     "shell.execute_reply": "2025-11-12T15:57:11.346086Z",
     "shell.execute_reply.started": "2025-11-12T15:57:11.334705Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "afshkasf\n"
     ]
    }
   ],
   "source": [
    "print(\"afshkasf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acc7f74c-d720-4688-b8e4-cb82ea6eb2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading batch of 2 from s3://mybucket/data-delta/...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_explorative_take_batch pid=721)\u001b[0m Estimated parquet encoding ratio is 6.463.\n",
      "\u001b[36m(_explorative_take_batch pid=721)\u001b[0m Estimated parquet reader batch size at 163881 rows\n",
      "\u001b[36m(_explorative_take_batch pid=721)\u001b[0m A new progress UI is available. To enable, set `ray.data.DataContext.get_current().enable_rich_progress_bars = True`.\n",
      "\u001b[36m(_explorative_take_batch pid=721)\u001b[0m Registered dataset logger for dataset dataset_1_0\n",
      "\u001b[36m(_explorative_take_batch pid=721)\u001b[0m Starting execution of Dataset dataset_1_0. Full logs are in /tmp/ray/session_2025-11-16_01-40-37_726515_8/logs/ray-data\n",
      "\u001b[36m(_explorative_take_batch pid=721)\u001b[0m Execution plan of Dataset dataset_1_0: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> LimitOperator[limit=64]\n",
      "\u001b[36m(_explorative_take_batch pid=721)\u001b[0m ‚ö†Ô∏è  Ray's object store is configured to use only 42.9% of available memory (11.2GiB out of 26.1GiB total). For optimal Ray Data performance, we recommend setting the object store to at least 50% of available memory. You can do this by setting the 'object_store_memory' parameter when calling ray.init() or by setting the RAY_DEFAULT_OBJECT_STORE_MEMORY_PROPORTION environment variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Read complete.\n",
      "    Table_id           Session_ID  Interface_ID  Session_Indicator  \\\n",
      "0       3101  1305130618271289494             1                  2   \n",
      "1       3101  1305130623311911163             1                  1   \n",
      "2       3101  1310130612364021039             5                  0   \n",
      "3       3101  1313130612004547216             5                  1   \n",
      "4       3101  1313130612297575526             5                  1   \n",
      "..       ...                  ...           ...                ...   \n",
      "59      3101  1615130615845827034             1                  1   \n",
      "60      3101  1616130612126845847             5                  0   \n",
      "61      3101  1619130611854250045             5                  1   \n",
      "62      3101  1630130611899009063             5                  1   \n",
      "63      3101  1632130622846648899             1                  1   \n",
      "\n",
      "    Start_Time_s  Start_Time_ms  End_Time_s  End_Time_ms  Protocol_Category  \\\n",
      "0     1754927850             64  1754927851           67                  4   \n",
      "1     1754928354            399  1754928355          769                  4   \n",
      "2     1754927260            320  1754927261           40                  4   \n",
      "3     1754927202            863  1754927225           42                  4   \n",
      "4     1754927182             44  1754927253          644                  4   \n",
      "..           ...            ...         ...          ...                ...   \n",
      "59    1754927606            516  1754927608          367                  4   \n",
      "60    1754927236            338  1754927236          647                  4   \n",
      "61    1754927208            872  1754927210           82                  4   \n",
      "62    1754927212            756  1754927213          406                  4   \n",
      "63    1754928305            740  1754928308          157                  4   \n",
      "\n",
      "    Protocol  ...  DL_TRANS_DELAY  UL_TRANS_DELAY  AVG_UL_RTT_MICRO_SEC  \\\n",
      "0      48000  ...               1               2                   901   \n",
      "1      48000  ...             638            1096                   573   \n",
      "2         17  ...               1               4                   372   \n",
      "3      48000  ...           21938           21114                   788   \n",
      "4      48000  ...           71529           61166                   259   \n",
      "..       ...  ...             ...             ...                   ...   \n",
      "59     48000  ...            1144            1161                   157   \n",
      "60     45557  ...              38              27                   405   \n",
      "61     48000  ...              32            1180                   499   \n",
      "62     48000  ...             143             518                   505   \n",
      "63     48000  ...            1311              62                   396   \n",
      "\n",
      "    AVG_DW_RTT_MICRO_SEC  ERROR_CODE_4xx_TIMES  ERROR_CODE_5xx_TIMES  \\\n",
      "0                    486                   NaN                   NaN   \n",
      "1                    905                   NaN                   NaN   \n",
      "2                    371                   0.0                   0.0   \n",
      "3                    145                   NaN                   NaN   \n",
      "4                    888                   NaN                   NaN   \n",
      "..                   ...                   ...                   ...   \n",
      "59                   227                   NaN                   NaN   \n",
      "60                   547                   NaN                   NaN   \n",
      "61                   663                   NaN                   NaN   \n",
      "62                   816                   NaN                   NaN   \n",
      "63                   950                   NaN                   NaN   \n",
      "\n",
      "   GET_TIMEOUT_NUM POST_TO_NUM  Flag  RECORD_DATE_TEHRAN  \n",
      "0              NaN         NaN     0 2025-08-11 19:27:30  \n",
      "1              NaN         NaN     0 2025-08-11 19:35:54  \n",
      "2              0.0         0.0     0 2025-08-11 19:17:40  \n",
      "3              NaN         NaN     0 2025-08-11 19:16:42  \n",
      "4              NaN         NaN     0 2025-08-11 19:16:22  \n",
      "..             ...         ...   ...                 ...  \n",
      "59             NaN         NaN     0 2025-08-11 19:23:26  \n",
      "60             NaN         NaN     0 2025-08-11 19:17:16  \n",
      "61             NaN         NaN     0 2025-08-11 19:16:48  \n",
      "62             NaN         NaN     0 2025-08-11 19:16:52  \n",
      "63             NaN         NaN     0 2025-08-11 19:35:05  \n",
      "\n",
      "[64 rows x 134 columns]\n",
      "Initiating writer for s3://mybucket/data-delta/ in 'append' mode...\n",
      "...Writer initiated.\n",
      "Writing batch back to s3://mybucket/data-delta/...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_explorative_take_batch pid=721)\u001b[0m ‚úîÔ∏è  Dataset dataset_1_0 execution finished in 6.12 seconds\n"
     ]
    },
    {
     "ename": "RayTaskError(CommitFailedError)",
     "evalue": "\u001b[36mray::DeltaWriter.write_batch()\u001b[39m (pid=718, ip=172.19.0.3, actor_id=fde39fd2b7b67f5c44f9fd8e01000000, repr=<my_platform_sdk.DeltaWriter object at 0x757dfb0e7d70>)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/my_platform_sdk/__init__.py\", line 154, in write_batch\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/my_platform_sdk/__init__.py\", line 141, in _init_table_if_needed\n  File \"/home/ray/anaconda3/lib/python3.12/site-packages/deltalake/writer/writer.py\", line 131, in write_deltalake\n    table._table.write(\n_internal.CommitFailedError: Writer features must be specified for writerversion >= 7, please specify: TimestampWithoutTimezone",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRayTaskError(CommitFailedError)\u001b[39m           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mWriting batch back to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdelta_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m write_future = sdk.write_data(writer_actor, batch_to_write)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[43mray\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrite_future\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# <- now valid\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m...Write complete!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/ray/_private/auto_init_hook.py:22\u001b[39m, in \u001b[36mwrap_auto_init.<locals>.auto_init_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mauto_init_wrapper\u001b[39m(*args, **kwargs):\n\u001b[32m     21\u001b[39m     auto_init_ray()\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/ray/_private/client_mode_hook.py:103\u001b[39m, in \u001b[36mclient_mode_hook.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m client_mode_should_convert():\n\u001b[32m    100\u001b[39m     \u001b[38;5;66;03m# Legacy code\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;66;03m# we only convert init function if RAY_CLIENT_MODE=1\u001b[39;00m\n\u001b[32m    102\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m func.\u001b[34m__name__\u001b[39m != \u001b[33m\"\u001b[39m\u001b[33minit\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/ray/util/client/api.py:42\u001b[39m, in \u001b[36m_ClientAPI.get\u001b[39m\u001b[34m(self, vals, timeout)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, vals, *, timeout=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     36\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"get is the hook stub passed on to replace `ray.get`\u001b[39;00m\n\u001b[32m     37\u001b[39m \n\u001b[32m     38\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[33;03m        vals: [Client]ObjectRef or list of these refs to retrieve.\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[33;03m        timeout: Optional timeout in milliseconds\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mworker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/ray/util/client/worker.py:433\u001b[39m, in \u001b[36mWorker.get\u001b[39m\u001b[34m(self, vals, timeout)\u001b[39m\n\u001b[32m    431\u001b[39m     op_timeout = max_blocking_operation_time\n\u001b[32m    432\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m433\u001b[39m     res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_get\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    434\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    435\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m GetTimeoutError:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/ray/util/client/worker.py:461\u001b[39m, in \u001b[36mWorker._get\u001b[39m\u001b[34m(self, ref, timeout)\u001b[39m\n\u001b[32m    459\u001b[39m         logger.exception(\u001b[33m\"\u001b[39m\u001b[33mFailed to deserialize \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(chunk.error))\n\u001b[32m    460\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m461\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[32m    462\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunk.total_size > OBJECT_TRANSFER_WARNING_SIZE \u001b[38;5;129;01mand\u001b[39;00m log_once(\n\u001b[32m    463\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mclient_object_transfer_size_warning\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    464\u001b[39m ):\n\u001b[32m    465\u001b[39m     size_gb = chunk.total_size / \u001b[32m2\u001b[39m**\u001b[32m30\u001b[39m\n",
      "\u001b[31mRayTaskError(CommitFailedError)\u001b[39m: \u001b[36mray::DeltaWriter.write_batch()\u001b[39m (pid=718, ip=172.19.0.3, actor_id=fde39fd2b7b67f5c44f9fd8e01000000, repr=<my_platform_sdk.DeltaWriter object at 0x757dfb0e7d70>)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/my_platform_sdk/__init__.py\", line 154, in write_batch\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/my_platform_sdk/__init__.py\", line 141, in _init_table_if_needed\n  File \"/home/ray/anaconda3/lib/python3.12/site-packages/deltalake/writer/writer.py\", line 131, in write_deltalake\n    table._table.write(\n_internal.CommitFailedError: Writer features must be specified for writerversion >= 7, please specify: TimestampWithoutTimezone"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "delta_path = \"s3://mybucket/data-delta/\"\n",
    "\n",
    "print(f\"Reading batch of 2 from {delta_path}...\")\n",
    "batch_to_write = ray.get(sdk.explorative_take_batch.remote(delta_path, batch_format=\"pandas\"))\n",
    "print(\"...Read complete.\")\n",
    "print(batch_to_write)\n",
    "\n",
    "print(f\"Initiating writer for {delta_path} in 'append' mode...\")\n",
    "writer_actor = sdk.initiate_data_writer(delta_path, mode=\"append\")\n",
    "print(\"...Writer initiated.\")\n",
    "\n",
    "print(f\"Writing batch back to {delta_path}...\")\n",
    "write_future = sdk.write_data(writer_actor, batch_to_write)\n",
    "ray.get(write_future)  # <- now valid\n",
    "print(\"...Write complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5946a4d2-3c90-42a4-ab80-5e84cd523d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = sdk.TrainConfig(\n",
    "    model_name=\"TrainClassTest\",\n",
    "    delta_path=\"s3://mybucket/data-delta/\",\n",
    "    epochs=2,\n",
    "    batch_size=50,\n",
    "    num_workers=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d4cee86-bd4d-4974-968b-a8e3443706ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTrainer(sdk.BaseTrainWorker):\n",
    "    def init_model(self):\n",
    "        return {\"w\": 0.0}\n",
    "\n",
    "    def initialize(self):\n",
    "        print(\"[User] Init step\")\n",
    "\n",
    "    def train_step(self, model, batch, epoch, config):\n",
    "        x = batch[\"x\"]\n",
    "        model[\"w\"] += sum(x) * 0.01\n",
    "        return {\"update\": float(model[\"w\"])}\n",
    "\n",
    "    def post_epoch(self, epoch, metrics):\n",
    "        print(f\"[User] Post epoch {epoch}, metrics_count={len(metrics)}\")\n",
    "\n",
    "    def post_train(self, final_metrics):\n",
    "        print(\"[User] Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86455e6b-129a-44e0-a3e6-61ebd503f408",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m result = \u001b[43mtrain\u001b[49m(MyTrainer, config)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[31mNameError\u001b[39m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "result = train(MyTrainer, config)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58aa4714-aa42-4b44-9f44-300b46a1e2a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T16:58:05.858367Z",
     "iopub.status.busy": "2025-11-16T16:58:05.857890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TrainWorkerActor pid=172, ip=172.19.0.5)\u001b[0m [Worker] Running setup...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TrainWorkerActor pid=172, ip=172.19.0.5)\u001b[0m Estimated parquet encoding ratio is 6.463.\n",
      "\u001b[36m(TrainWorkerActor pid=172, ip=172.19.0.5)\u001b[0m Estimated parquet reader batch size at 163881 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Driver] Starting epoch 0\n",
      "\u001b[36m(TrainWorkerActor pid=172, ip=172.19.0.5)\u001b[0m [User] Init step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TrainWorkerActor pid=172, ip=172.19.0.5)\u001b[0m A new progress UI is available. To enable, set `ray.data.DataContext.get_current().enable_rich_progress_bars = True`.\n",
      "\u001b[36m(TrainWorkerActor pid=172, ip=172.19.0.5)\u001b[0m Registered dataset logger for dataset dataset_1_0\n",
      "\u001b[36m(TrainWorkerActor pid=172, ip=172.19.0.5)\u001b[0m Starting execution of Dataset dataset_1_0. Full logs are in /tmp/ray/session_2025-11-16_08-50-27_483778_7/logs/ray-data\n",
      "\u001b[36m(TrainWorkerActor pid=172, ip=172.19.0.5)\u001b[0m Execution plan of Dataset dataset_1_0: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> AllToAllOperator[RandomShuffle]\n",
      "\u001b[36m(TrainWorkerActor pid=172, ip=172.19.0.5)\u001b[0m ‚ö†Ô∏è  Ray's object store is configured to use only 42.9% of available memory (11.2GiB out of 26.1GiB total). For optimal Ray Data performance, we recommend setting the object store to at least 50% of available memory. You can do this by setting the 'object_store_memory' parameter when calling ray.init() or by setting the RAY_DEFAULT_OBJECT_STORE_MEMORY_PROPORTION environment variable.\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Dict\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "# ============================================================\n",
    "# 0. CONFIG\n",
    "# ============================================================\n",
    "# user side\n",
    "@dataclass\n",
    "class TrainConfig:\n",
    "    model_name: str\n",
    "    delta_path: str             # Delta table path\n",
    "    epochs: int\n",
    "    batch_size: int\n",
    "    num_workers: int\n",
    "    shuffle_each_epoch: bool = True\n",
    "    user_params: Dict[str, Any] = field(default_factory=dict)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1. BASE TRAIN WORKER (USER IMPLEMENTS THIS)\n",
    "# ============================================================\n",
    "\n",
    "# user side\n",
    "class BaseTrainWorker(ABC):\n",
    "    def __init__(self, config: TrainConfig):\n",
    "        self.config = config\n",
    "        self.model = None\n",
    "\n",
    "    @abstractmethod\n",
    "    def init_model(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def initialize(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def train_step(self, model, batch, epoch: int, config: TrainConfig):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def post_epoch(self, epoch: int, metrics):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def post_train(self, final_metrics):\n",
    "        pass\n",
    "\n",
    "    # Protected internal methods\n",
    "    def _setup(self):\n",
    "        self.model = self.init_model()\n",
    "        if self.model is None:\n",
    "            raise RuntimeError(\"init_model() must return a model/state object\")\n",
    "        self.initialize()\n",
    "\n",
    "    def _train_epoch(self, batch_iter, epoch: int):\n",
    "        all_metrics = []\n",
    "        for batch_idx, batch in enumerate(batch_iter):\n",
    "            metrics = self.train_step(self.model, batch, epoch, self.config)\n",
    "            metrics[\"batch\"] = batch_idx\n",
    "            print(f\"[Worker] Epoch={epoch} Batch={batch_idx} Metrics={metrics}\")\n",
    "            all_metrics.append(metrics)\n",
    "        self.post_epoch(epoch, all_metrics)\n",
    "\n",
    "        # register the model could be here\n",
    "        _register_model(self.model, self.config.model_name)\n",
    "\n",
    "        return all_metrics\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. TRAIN WORKER (RAY ACTOR)\n",
    "# ============================================================\n",
    "\n",
    "@ray.remote\n",
    "class TrainWorkerActor:\n",
    "    def __init__(self, trainer_cls, config: TrainConfig):\n",
    "        self.config = config\n",
    "        self.trainer = trainer_cls(config)\n",
    "\n",
    "        # Lazy dataset load (inside actor!)\n",
    "        self.dataset = None\n",
    "\n",
    "    def setup(self):\n",
    "        print(\"[Worker] Running setup...\")\n",
    "        self.dataset = ray.data.read_delta(self.config.delta_path)\n",
    "        self.trainer._setup()\n",
    "\n",
    "    def train_epoch(self, epoch: int):\n",
    "        # shuffle per epoch\n",
    "        ds_epoch = self.dataset.random_shuffle() if self.config.shuffle_each_epoch else self.dataset\n",
    "        # shard for this worker (dataset split by total workers)\n",
    "        shards = ds_epoch.split(self.config.num_workers)\n",
    "        worker_idx = ray.get_runtime_context().get_worker_id() % self.config.num_workers\n",
    "        shard = shards[worker_idx]\n",
    "\n",
    "        batch_iter = shard.iter_batches(batch_size=self.config.batch_size)\n",
    "        return self.trainer._train_epoch(batch_iter, epoch)\n",
    "\n",
    "    def finalize(self, final_metrics):\n",
    "        return self.trainer.post_train(final_metrics)\n",
    "\n",
    "    def get_model(self):\n",
    "        return self.trainer.model\n",
    "# user side\n",
    "def train(trainer_cls, config: TrainConfig):\n",
    "    trainer = BaseTrainer(config=config, trainer_cls=trainer_cls)\n",
    "    return trainer.train()\n",
    "\n",
    "# ============================================================\n",
    "# 3. DRIVER TRAINER\n",
    "# ============================================================\n",
    "\n",
    "class BaseTrainer:\n",
    "    def __init__(self, config: TrainConfig, trainer_cls):\n",
    "        self.config = config\n",
    "        self.trainer_cls = trainer_cls\n",
    "\n",
    "    def train(self):\n",
    "        # create actors\n",
    "        workers = [TrainWorkerActor.remote(self.trainer_cls, self.config)\n",
    "                   for _ in range(self.config.num_workers)]\n",
    "\n",
    "        # setup (dataset + model)\n",
    "        ray.get([w.setup.remote() for w in workers])\n",
    "\n",
    "        all_epochs_results = []\n",
    "\n",
    "        for epoch in range(self.config.epochs):\n",
    "            print(f\"[Driver] Starting epoch {epoch}\")\n",
    "            futs = [w.train_epoch.remote(epoch) for w in workers]\n",
    "            epoch_results = ray.get(futs)\n",
    "            all_epochs_results.append(epoch_results)\n",
    "\n",
    "        # finalize\n",
    "        for w in workers:\n",
    "            w.finalize.remote(all_epochs_results)\n",
    "\n",
    "        # collect models\n",
    "        models = ray.get([w.get_model.remote() for w in workers])\n",
    "        return {\"metrics\": all_epochs_results, \"models\": models}\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. USER SIDE SDK\n",
    "# ============================================================\n",
    "\n",
    "# sdk.BaseTrainWorker\n",
    "#sdk.train\n",
    "\n",
    "# ============================================================\n",
    "# 5. USER TRAINER EXAMPLE\n",
    "# ============================================================\n",
    "\n",
    "class MyTrainer(BaseTrainWorker):\n",
    "    def init_model(self):\n",
    "        return {\"w\": 0.0}\n",
    "\n",
    "    def initialize(self):\n",
    "        print(\"[User] Init step\")\n",
    "\n",
    "    def train_step(self, model, batch, epoch, config):\n",
    "        x = batch[\"x\"]\n",
    "        model[\"w\"] += sum(x) * 0.01\n",
    "        return {\"update\": float(model[\"w\"])}\n",
    "\n",
    "    def post_epoch(self, epoch, metrics):\n",
    "        print(f\"[User] Post epoch {epoch}, metrics_count={len(metrics)}\")\n",
    "\n",
    "    def post_train(self, final_metrics):\n",
    "        print(\"[User] Training complete.\")\n",
    "\n",
    "\n",
    "config = TrainConfig(\n",
    "    model_name=\"afdaf\",\n",
    "    delta_path=\"s3://mybucket/data-delta/\",\n",
    "    epochs=2,\n",
    "    batch_size=50,\n",
    "    num_workers=1\n",
    ")\n",
    "\n",
    "result =  train(MyTrainer, config)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba9ecd97-717e-4211-89df-4f62eee7da42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T17:12:04.489210Z",
     "iopub.status.busy": "2025-11-16T17:12:04.488898Z",
     "iopub.status.idle": "2025-11-16T17:12:04.789409Z",
     "shell.execute_reply": "2025-11-16T17:12:04.788484Z",
     "shell.execute_reply.started": "2025-11-16T17:12:04.489185Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MyModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m Model = sdk.load_model(\u001b[43mMyModel\u001b[49m, \u001b[32m10\u001b[39m)\n\u001b[32m      2\u001b[39m sdk.start_run(\u001b[33m\"\u001b[39m\u001b[33mRun\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m sdk.register_model(Model, \u001b[33m\"\u001b[39m\u001b[33mModellll\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'MyModel' is not defined"
     ]
    }
   ],
   "source": [
    "Model = sdk.load_model(MyModel, 10)\n",
    "sdk.start_run(\"Run\")\n",
    "sdk.register_model(Model, \"Modellll\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1593e388-a982-43f2-aed4-4d3bae8e2605",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
